<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="《纵向联邦预测模型的特征推理攻击》阅读笔记"><title>Feature Inference Attack on Model Predictions in Vertical Federated Learning</title><link rel=canonical href=https://lbqaq.top/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/><link rel=stylesheet href=/scss/style.min.ae1eb7f887336befbb146467b4baee8138bb2b0004f1f7aa9fcf3b40efa7e299.css><meta property='og:title' content="Feature Inference Attack on Model Predictions in Vertical Federated Learning"><meta property='og:description' content="《纵向联邦预测模型的特征推理攻击》阅读笔记"><meta property='og:url' content='https://lbqaq.top/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/'><meta property='og:site_name' content='luoboQAQ'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='联邦学习'><meta property='article:tag' content='推理攻击'><meta property='article:published_time' content='2023-01-03T16:27:11+08:00'><meta property='article:modified_time' content='2023-01-03T16:27:11+08:00'><meta property='og:image' content='https://lbqaq.top/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/100018879.webp'><meta name=twitter:title content="Feature Inference Attack on Model Predictions in Vertical Federated Learning"><meta name=twitter:description content="《纵向联邦预测模型的特征推理攻击》阅读笔记"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://lbqaq.top/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/100018879.webp'><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><style>:root{--sys-font-family:-apple-system, "LXGW WenKai", 'Microsoft Yahei', 'WenQuanYi Micro Hei', sans-serif;--code-font-family:"JetBrains Mono", "LXGW WenKai Mono", Menlo, Monaco, Consolas, monospace;--article-font-family:"LXGW WenKai", sans-serif;--base-font-family:"LXGW WenKai", var(--sys-font-family), sans-serif}</style><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","smhd51txrk")</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/Mint_hu_90cbcbb19cfdb02a.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🌞</span></figure><div class=site-meta><h1 class=site-name><a href=/>luoboQAQ</a></h1><h2 class=site-description>快乐学习每一天</h2></div></header><ol class=menu-social><li><a href=https://github.com/luoboQAQ target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://lbqaq.top/index.xml target=_blank title=RSS订阅 rel=me><svg class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li><li><a href=https://pan.lbqaq.top target=_blank title=我的个人云盘 rel=me><svg class="icon icon-tabler icon-tabler-cloud" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M7 18a4.6 4.4.0 010-9 5 4.5.0 0111 2h1a3.5 3.5.0 010 7H7"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>文章</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>查询</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>友链</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#介绍>介绍</a><ol><li><a href=#相关研究>相关研究</a></li><li><a href=#本文贡献>本文贡献</a></li></ol></li><li><a href=#问题构造>问题构造</a><ol><li><a href=#系统模型>系统模型</a></li><li><a href=#威胁模型>威胁模型</a></li></ol></li><li><a href=#攻击方法>攻击方法</a><ol><li><a href=#逻辑回归模型lr的等式求解攻击>逻辑回归模型(LR)的等式求解攻击</a><ol><li><a href=#二分类逻辑回归>二分类逻辑回归</a></li><li><a href=#多分类逻辑回归>多分类逻辑回归</a></li></ol></li><li><a href=#决策树模型的路径限制攻击>决策树模型的路径限制攻击</a></li><li><a href=#生成回归网络攻击>生成回归网络攻击</a></li><li><a href=#随机森林的生成模型的攻击>随机森林的生成模型的攻击</a></li></ol></li><li><a href=#实验评价>实验评价</a><ol><li><a href=#d_target对等式求解攻击的影响>$d_{target}$对等式求解攻击的影响</a></li><li><a href=#d_target对路径限制攻击的影响>$d_{target}$对路径限制攻击的影响</a></li><li><a href=#d_target对生成回归网络攻击的影响>$d_{target}$对生成回归网络攻击的影响</a></li><li><a href=#需要预测的样本数对生成回归网络攻击的影响>需要预测的样本数对生成回归网络攻击的影响</a></li><li><a href=#数据相关性对生成回归网络攻击的影响>数据相关性对生成回归网络攻击的影响</a></li></ol></li><li><a href=#对策>对策</a></li><li><a href=#参考文章>参考文章</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/100018879.webp width=2833 height=1814 loading=lazy alt="Featured image of post Feature Inference Attack on Model Predictions in Vertical Federated Learning"></a></div><div class=article-details><header class=article-category><a href=/categories/%E8%AE%BA%E6%96%87/>论文</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/>Feature Inference Attack on Model Predictions in Vertical Federated Learning</a></h2><h3 class=article-subtitle>《纵向联邦预测模型的特征推理攻击》阅读笔记</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2023-01-03</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 13 分钟</time></div></footer></div></header><section class=article-content><h2 id=介绍><a href=#%e4%bb%8b%e7%bb%8d class=header-anchor></a>介绍</h2><p>近年来，人们对利用来自多个组织的分布式源的数据来设计复杂的机器学习模型越来越感兴趣。</p><p>但是，由于</p><ul><li>用户敏感数据的使用被迫遵守标准隐私规章或法律，例如GDPR或CCPA</li><li>数据是组织保持业务竞争优势的宝贵资产，应该受到高度保护</li></ul><p>这两个原因，专有数据不能被直接共享。于是，<strong>联邦学习</strong>便被提出。联邦学习是一种新兴的数据协作范例，它允许多个数据所有者联合构建ML模型而不向彼此泄露其私有数据。</p><p>联邦学习根据数据划分，被分为横向联邦学习、纵向联邦学习、联邦迁移学习三类。在本文中，作者主要考虑的是纵向联邦学习这一类。何为纵向联邦学习呢？也就是２个数据集的用户重叠部分较大，而用户特征重叠部分较小，作者给出了一个实例：</p><p>一家银行希望构建一个机器学习模型，通过加入Fintech公司的更多特性来评估是否批准用户的信用卡申请。这家银行拥有“年龄”和“收入”的特征，而Fintech公司拥有“存款”和“平均在线购物次数”的特征。只有银行拥有训练数据集和测试数据集中的标签信息，即：是否应批准申请。我们将带有标签的一方称为主动方，其余没有标签值的一方或者几方称为被动方。</p><p>在本篇文章中，把拥有标签值的一方看作进攻方，而没有标签值的一方或者几方所拥有的特征值看作目标值，进攻方通过一定的方法得到目标方的目标值，也就是通常模型中被动方的隐私数据。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101100642620.png width=1050 height=609 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101100642620_hu_d078401738fac925.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101100642620_hu_1a69e51281fcb2c0.png 1024w" loading=lazy alt=纵向联邦学习示例 class=gallery-image data-flex-grow=172 data-flex-basis=413px></p><h3 id=相关研究><a href=#%e7%9b%b8%e5%85%b3%e7%a0%94%e7%a9%b6 class=header-anchor></a>相关研究</h3><ul><li>Comprehensive privacy analysis of deep learning: Stand-alone and federated learning under passive and active white-box inference attacks</li><li>The secret sharer: Measuring unintended neural network memorization & extracting secrets</li><li>Exploiting unintended feature leakage in collaborative learning</li><li>Deep models under the gan: information leakage from collaborative deep learning</li></ul><p>等等，这些文章旨在推断横向联邦学习中参与方的特征值，其中各方具有相同的特征但具有不同的样本。 然而，这些攻击极大地依赖于在训练过程中交换的模型梯度，一旦模型梯度被安全地保护，这些攻击将是无效的。而且，对于预测阶段中的推理攻击，联邦学习模型事先不知道预测样本。于是，作者提出几种基于模型预测的特征推理攻击，研究了纵向联邦学习预测阶段的隐私泄露问题，该攻击方法在预测输出的计算过程中不依赖任何中间信息。</p><h3 id=本文贡献><a href=#%e6%9c%ac%e6%96%87%e8%b4%a1%e7%8c%ae class=header-anchor></a>本文贡献</h3><ul><li>首次提出了纵向联邦学习预测模型的特征推理攻击</li><li>提出了针对逻辑回归和决策树的两种特定的攻击思路</li><li>利用攻方积累的多种预测输出，来设计一种从中学习攻方特征和目标特征关联的通用攻击思路</li><li>在真实和合成的数据集上，实践了提出的方法并进行了大量的评估。结论显示了攻击的有效性，本文也分析和建议了几种潜在的应对思路</li></ul><h2 id=问题构造><a href=#%e9%97%ae%e9%a2%98%e6%9e%84%e9%80%a0 class=header-anchor></a>问题构造</h2><h3 id=系统模型><a href=#%e7%b3%bb%e7%bb%9f%e6%a8%a1%e5%9e%8b class=header-anchor></a>系统模型</h3><p>我们考虑一组m个分布方（或数据所有者）${P_1,&mldr;,P_m}$，他们通过合并各自的数据集来训练纵向联邦学习模型。在获得经训练的纵向联邦学习模型参数$\theta$之后，各方协作地对其联合预测数据集$D_{pred}={D_1,&mldr;,D_m}$进行预测。 数据集中的每一行对应一个样本，每一列对应一个要素。 设$n$为样本数，$d_i$为$D_i$中的特征数，其中$i\in{1,&mldr;,m}$。我们表示$D_i={x^t_i}^n_{t=1}$，其中$x^t_i$表示$D_i$的第t个样本。在这篇文章中，作者考虑监督分类任务，并用$c$表示分类的数量。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101115423656.png width=1017 height=715 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101115423656_hu_463b64018c45090d.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101115423656_hu_9ccfddf49fb88dee.png 1024w" loading=lazy alt=符号说明 class=gallery-image data-flex-grow=142 data-flex-basis=341px></p><h3 id=威胁模型><a href=#%e5%a8%81%e8%83%81%e6%a8%a1%e5%9e%8b class=header-anchor></a>威胁模型</h3><p>我们考虑半诚实模型，其中每一方都严格按照规定遵循协议，但可能试图基于接收到的消息推断其他方的私有信息。具体而言，本文着重研究了主动方为对抗方的情形。主动方还可以与其他被动方串通来推断一组目标被动方的私有特征值。最强的概念是m-1个参与方（包括主动方）合谋推断其余被动方的特征值。</p><h2 id=攻击方法><a href=#%e6%94%bb%e5%87%bb%e6%96%b9%e6%b3%95 class=header-anchor></a>攻击方法</h2><h3 id=逻辑回归模型lr的等式求解攻击><a href=#%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92%e6%a8%a1%e5%9e%8blr%e7%9a%84%e7%ad%89%e5%bc%8f%e6%b1%82%e8%a7%a3%e6%94%bb%e5%87%bb class=header-anchor></a>逻辑回归模型(LR)的等式求解攻击</h3><p>给定预测输出$v$，对手$P_{adv}$可以构造一组方程，$P_{adv}$可以从该组方程推断出$P_{target}$所持有的特征值。也就是说攻击者利用纵向联邦学习预测结果以及自己所持有的参数推断数据其他提供方的参数。</p><p>作者分别讨论了二分类逻辑回归以及多分类逻辑回归。</p><h4 id=二分类逻辑回归><a href=#%e4%ba%8c%e5%88%86%e7%b1%bb%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92 class=header-anchor></a>二分类逻辑回归</h4><p>将模型参数表示为$\theta = \theta (\theta_{adv},\theta_{target})$，其中$\theta_{adv}$和$\theta_{target}$分别是对应于$P_{adv}$和$P_{target}$所拥有的特征的权重。</p><p>令$v$为给定样本$x=(x_{adv},x_{target})$的预测输出。对于二元LR分类，$v$中只有一个有意义的置信度分数，我们令其为$v_1$。</p><p>给定$v_1$和对手自己的特征值$x_{adv}$，$P_{adv}$可以直接创建以$x_{target}$作为变量的方程，即，</p>$$\sigma\left(x\_{\text {adv }} \cdot \theta\_{\text {adv }}+x\_{\text {target }} \cdot \theta\_{\text {target }}\right)=v\_{1}$$<p>其中$\sigma(\cdot)$是S形函数。显然，如果只有一个未知特征，即，$d_{target} = 1$，则方程只有一个解，这意味着可以精确地推断未知特征值$x_{target}$。</p><h4 id=多分类逻辑回归><a href=#%e5%a4%9a%e5%88%86%e7%b1%bb%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92 class=header-anchor></a>多分类逻辑回归</h4><p>对于多分类逻辑回归，存在$c$个线性回归模型。设$\theta = (\theta^{(1)},&mldr;,\theta^{(c)})$分别为这些$c$模型的参数。</p><p>为了发起特征推理攻击，对手的目标是构造$k\in{1,&mldr;,c}$的线性方程。</p>$$x \_ { a d v } \cdot \theta \_ { a d v } ^ { ( k ) } + x \_ { target } \cdot \theta \_ { target } ^ { ( k ) } = z \_ { k }$$<p>其中$z_k$是第$k$个线性回归模型的输出。然而，$P_{adv}$只知道置信度向量$v =(v_1,&mldr;,v_c)$，使得</p>$$v \_ { k } = \frac { e x p ( z \_ { k } ) } { \sum \_ { k' } exp ( z \_ { k' } ) }$$<p>上面两个式子是我们用逻辑回归解决多分类问题的通用的公式，其中作者在第一个式子中把x和θ分成了攻方和目标方的数据。</p><p>作者将第二个式子双方取对数</p>$$\ln v \_ { k } = z \_ { k } - \ln ( \sum \_ { k ^ { \prime } } e x p ( z \_ { k } ^ { \prime } ) )$$<p>等式右边的第二项对于所有$k\in{1,&mldr;,c}$是相同的。因此，对两个相邻类别概率v的对数取差值</p>$$\ln v \_ { k } - \ln v \_ { k'} = z \_ { k } - z \_ { k' }$$<p>最后可以得到一个无关z值的一个等式</p>$$x\_{\text {adv }}\left(\theta\_{\text {adv }}^{(k)}-\theta\_{\text {adv }}^{(k+1)}\right)+x\_{\text {target }}\left(\theta\_{\text {target }}^{(k)}-\theta\_{\text {target }}^{(k+1)}\right)=a\_{k}^{\prime}$$<p>其中$a^\prime_k=\ln v_k-\ln v_{k+1},k\in{1,&mldr;,c}$。</p><p>但是在后面推理的时候本文有一些为了逻辑上方便而采用了一个把纵向联邦限制减少的做法：把目标方或者说被动方的参数θ看作进攻方或者主动方能够得到的数据。</p><p>实际情况中，主动方或者进攻方在一般的纵向联邦框架中是无法得到被动方的参数θ数据的。</p><p>本文中我们姑且认为进攻方能得到，那么上式中的未知数只有$x_{target}$了，而$x_{target}$的维数为$d_{target}$，数量为目标方所用拥有的特征数。</p><p>这里我们把$x_{target}$的未知数看作自变量，个数为目标放所拥有的特征数。那么也就是说，$d_{target}$个自变量，$c-1$个方程，当$d_{target}\le c-1$，那么$x_{target}$只有一个解，可以精确地推断出来。</p><h3 id=决策树模型的路径限制攻击><a href=#%e5%86%b3%e7%ad%96%e6%a0%91%e6%a8%a1%e5%9e%8b%e7%9a%84%e8%b7%af%e5%be%84%e9%99%90%e5%88%b6%e6%94%bb%e5%87%bb class=header-anchor></a>决策树模型的路径限制攻击</h3><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101155921474.png width=1016 height=673 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101155921474_hu_540bc76f19e55b86.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230101155921474_hu_50c4ce55f98ff4f2.png 1024w" loading=lazy alt=路径限制攻击示例 class=gallery-image data-flex-grow=150 data-flex-basis=362px></p><p>攻击方可以根据自己的部分特征信息(蓝色方框) 限制树模型中可能的路径(灰色箭头 -> 蓝色箭头 5:2)，结合预测类别结果<strong>1</strong>进一步限制决策路径(蓝色 - > 红色箭头 2:1 )，可以推测目标方Target的deposit属性(绿色方框) > 5K。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102101241766.png width=1043 height=1094 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102101241766_hu_9b0eac0701bccb27.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102101241766_hu_d7173bff23454079.png 1024w" loading=lazy alt=路径限制攻击算法 class=gallery-image data-flex-grow=95 data-flex-basis=228px></p><h3 id=生成回归网络攻击><a href=#%e7%94%9f%e6%88%90%e5%9b%9e%e5%bd%92%e7%bd%91%e7%bb%9c%e6%94%bb%e5%87%bb class=header-anchor></a>生成回归网络攻击</h3><p>上面介绍的两种攻击方式都是基于单个模型预测。然而，这些攻击很难应用于复杂的模型，如神经网络（NN）和随机森林（RF）。</p><p>针对上述缺陷，作者设计了一种基于多模型预测的通用特征推理攻击，即生成回归网络（GRN）攻击，这是本篇论文的重点。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102101712865.png width=1583 height=769 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102101712865_hu_b2d4bb9a5d4acaec.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102101712865_hu_e40be91b033b01c4.png 1024w" loading=lazy alt=生成回归网络攻击概况 class=gallery-image data-flex-grow=205 data-flex-basis=494px></p><p><strong>基本思想：</strong></p><p>计算出对手自身特征与攻击目标未知特征之间的总体相关性。在此基础上，推断未知特征值的问题等效于生成新值$\hat{x}_{target}$以匹配垂直FL模型的决策的问题，其中$\hat{x}_{target}$遵循由对手的已知特征值和特征相关性确定的概率分布。</p><p><strong>目标函数：</strong></p>$$\min \_{\theta\_{G}} \frac{1}{n} \sum\_{t=1}^{n} \ell\left(f\left(x\_{\mathrm{adv}}^{t}, f\_{G}\left(x\_{\mathrm{adv}}^{t}, r^{t} ; \theta\_{G}\right) ; \theta\right), v^{t}\right)+\Omega\left(f\_{G}\right)$$<p>其中$\theta$和$\theta_G$分别是纵向联邦学习模型和生成模型的参数。此外，$f_G$表示$\hat{x}_{target}^t$，即生成模型的输出,$f$表示给定所生成样本的纵向联邦学习模型的输出（由$x_{adv}^t$和$\hat{x}_{target}^t$连接）。此外，$\Omega(\cdot)$是生成的未知特征值${\hat{x}_{target}^t}_{t=1}^n$的正则化项。</p><p><strong>具体方法：</strong></p><ol><li><p>把进攻方所拥有的数据（蓝色）和随机生成的数据（橙色），合成一个d维向量，其中d为进攻方的特征数量和目标方特征数量之和，随机生成的数据是为了初始化生成模型的初始输入。</p></li><li><p>生成模型计算之后，输出生成模型对于目标方特征值的预测。</p></li><li><p>把生成模型生成的目标方特征值的预测（橙色）与进攻方所拥有的数据（蓝色）合并，得到另一个d维的向量，作为已经生成的纵向联邦学习预测模型（比如神经网络）的输入。</p></li><li><p>得到输出的对不同类别的预测概率矩阵（橙色），与真实的攻方特征值和目标方特征值得到的不同类别的预测概率矩阵（蓝色）求损失。</p></li><li><p>对得到的损失进行反向传播，修改生成模型的参数，得到新的生成模型对目标放特征值的预测。</p></li></ol><p>这种方法对于目标函数为可微的情况下效果不错，也就说明可以用来对逻辑回归和神经网络进行生成模型攻击。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102105356091.png width=1061 height=839 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102105356091_hu_1fd0979a015ca771.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102105356091_hu_103261bdcf884718.png 1024w" loading=lazy alt=GRN训练方法 class=gallery-image data-flex-grow=126 data-flex-basis=303px></p><h3 id=随机森林的生成模型的攻击><a href=#%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97%e7%9a%84%e7%94%9f%e6%88%90%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%94%bb%e5%87%bb class=header-anchor></a>随机森林的生成模型的攻击</h3><p>路径限制攻击不适用于随机森林的模型，特别是当随机森林的树数量很大的时候。</p><p>因此，在随机森林模型使用GRN攻击的思想。</p><p>但是，因为随机森林（RF）模型的目标函数并不是可微的，所以不能通过随机森林（RF）把预测损失反向传播给生成模型。</p><p>因此，本文在得到纵向联邦模型（比如随机森林RF）之后，攻方会另外训练一个可微的模型（比如神经网络NN）来近似RF模型。</p><h2 id=实验评价><a href=#%e5%ae%9e%e9%aa%8c%e8%af%84%e4%bb%b7 class=header-anchor></a>实验评价</h2><p><strong>数据集：</strong></p><p>四个数据集，分别是银行营销（20个特征的2分类），信用卡（23个特征的2分类），诊断（48个特征的11分类）和新闻流行（59个特征的5分类）。</p><p>此外，利用sklearn库生成了两个合成数据集，用于评估预测数据集中样本数n对生成回归网络攻击性能的影响。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102110409230.png width=1014 height=423 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102110409230_hu_3112a358cdab8e2b.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230102110409230_hu_a71ec3b9f1407162.png 1024w" loading=lazy alt=数据集概况 class=gallery-image data-flex-grow=239 data-flex-basis=575px></p><p><strong>指标：</strong></p><p>对于等式求解攻击（ESA）和生成回归网络攻击（GRNA），由于是回归任务，因此使用每个特征的均方误差（MSE）来衡量它们在重建多个目标特征时的总体准确性。具体而言，每个特征的MSE计算如下：</p>$$\mathrm{MSE}=\frac{1}{n * d\_{\text {target }}} \sum\_{t=1}^{n} \sum\_{i=1}^{d\_{\text {target }}}\left(\hat{x}\_{\text {target }, i}^{t}-x\_{\text {target }, i}^{t}\right)^{2}$$<p>对于路径限制攻击（PRA），作者测量了正确分支率（CBR）。</p><h3 id=d_target对等式求解攻击的影响><a href=#d_target%e5%af%b9%e7%ad%89%e5%bc%8f%e6%b1%82%e8%a7%a3%e6%94%bb%e5%87%bb%e7%9a%84%e5%bd%b1%e5%93%8d class=header-anchor></a>$d_{target}$对等式求解攻击的影响</h3><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103102116720.png width=2090 height=518 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103102116720_hu_44d855796c609ab7.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103102116720_hu_7d2b0e9c45c35dc3.png 1024w" loading=lazy alt=等式求解攻击性能 class=gallery-image data-flex-grow=403 data-flex-basis=968px></p><p>对于所有数据集，如果满足阈值条件$d_{target}\le c-1$（在每个子图中用“T”表示），则每个特征的MSE为0，这证明了上面讨论的性质正确。</p><p>通过观察b和c，我们发现即使不满足阈值条件，等式求解攻击仍然可以找到$x_{target}$的良好推断，这大大优于随机猜测方法。</p><p>还有一个明显的趋势，每个特征的MSE随着$d_{target}$分数的增加而增加，即攻方所掌握的特征数越少，供给的准确率越低。</p><p>同时，作者还分析了为什么Bank数据集的MSE增量远大于其他数据集的MSE增量，这是因为不同数据集的数据分布差异。</p><p>由伪逆矩阵计算出的解$\hat{x}_{target}$在所有解中具有最小的欧几里德范数，即$||\hat{x}_{target}||_2\le||x_{target}||_2$</p><p>其中</p>$$\sum\_{i=1}^{d\_{\text {target }}} \hat{x}\_{\text {target }, i}^{2} \leq \sum\_{i=1}^{d\_{\text {target }}} x\_{\text {target }, i}^{2}$$<p>因此，我们有</p>$$\begin{aligned}
\mathrm{MSE} & =\frac{1}{d\_{\text {target }}} \sum\_{i=1}^{d\_{\text {target }}}\left(\hat{x}\_{\text {target }, i}-x\_{\text {target }, i}\right)^{2} \\\\
& =\frac{1}{d\_{\text {target }}} \sum\_{i=1}^{d\_{\text {target }}}\left(\hat{x}\_{\text {target }, i}^{2}+x\_{\text {target }, i}^{2}-2 \hat{x}\_{\text {target }, i} x\_{\text {target }, i}\right) \\\\
& \leq \frac{1}{d\_{\text {target }}} \sum\_{i=1}^{d\_{\text {target }}}\left(\hat{x}\_{\text {target }, i}^{2}+x\_{\text {target }, i}^{2}\right) \\\\
& \leq \frac{1}{d\_{\text {target }}} \sum\_{i=1}^{d\_{\text {target }}} 2 x\_{\text {target }, i}^{2},
\end{aligned}$$<p>我们便推导出$\mathrm{MSE}(\hat{x}_{target},x_{target})$的上界。</p><p>作者分别计算了Bank、Credit、Drive和News四个数据集的上界，分别为0.60、0.14、0.45和0.34。</p><p>一般来说，上界越大，对手的攻击精度就越差。这就解释了为什么Bank的MSE比其他数据集增长得更快。</p><h3 id=d_target对路径限制攻击的影响><a href=#d_target%e5%af%b9%e8%b7%af%e5%be%84%e9%99%90%e5%88%b6%e6%94%bb%e5%87%bb%e7%9a%84%e5%bd%b1%e5%93%8d class=header-anchor></a>$d_{target}$对路径限制攻击的影响</h3><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103104636445.png width=2090 height=516 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103104636445_hu_7282c734e8457a43.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103104636445_hu_efe8e1a6cae3f776.png 1024w" loading=lazy alt=路径限制攻击性能 class=gallery-image data-flex-grow=405 data-flex-basis=972px></p><p>与等式求解攻击类似，攻击精度随着$d_{target}$的增加而降低。这是因为通常更多的目标特征将导致更多可能的预测路径，从而导致选择正确路径的概率降低。</p><p>我们可以发现，第三个数据集是异常的，它甚至随着$d_{target}$的增加而增加了。这是因为Drive数据集有11个类，比其他数据集的类要多得多。因此，在Drive中，每个类别对应的树形路径数量较少。其次，决策树模型在训练过程中只选择信息量大的特征，这意味着Drive数据集中$d_{target}$的增加不一定会增加树中未知特征的数量，因为有些特征可能永远不会被选中。</p><p>综上，较大的目标数据并不总是能降低路径限制攻击的CBR。</p><h3 id=d_target对生成回归网络攻击的影响><a href=#d_target%e5%af%b9%e7%94%9f%e6%88%90%e5%9b%9e%e5%bd%92%e7%bd%91%e7%bb%9c%e6%94%bb%e5%87%bb%e7%9a%84%e5%bd%b1%e5%93%8d class=header-anchor></a>$d_{target}$对生成回归网络攻击的影响</h3><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103111155894.png width=2090 height=525 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103111155894_hu_ec02b23a4ce8fbe.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103111155894_hu_6030528279424394.png 1024w" loading=lazy alt=生成回归网络攻击性能 class=gallery-image data-flex-grow=398 data-flex-basis=955px></p><p>作者展示了生成回归网络攻击对三种模型的攻击性能（LR：逻辑回归、RF：随机森林、NN：神经网络）</p><p>类似地，每个特征的MSE都随着$d_{target}$的增加而上升。这是因为生成回归网络攻击依赖于$x_{adv}$和$x_{target}$之间的特征相关性来推断未知特征值。如果$d_{target}$所占比例较大，学习到的相关性会变弱，导致攻击性能相对较差。然而，即使在$d_{target}$的分数为60%时，生成回归网络攻击仍然比随机猜测方法获得了更好的效果，证明了其有效性。</p><p>作者发现，采用神经网络模型的生成回归网络攻击的性能优于逻辑回归和随机森林模型。原因在于神经网络模型比其他两种模型具有更复杂的决策边界，从而极大地限制了给定相同$x_{adv}$和$v$时$x_{target}$的可能分布。同时，神经网络模型本身具有更多的参数，可以捕获更多关于特征相关性的重要信息，从而获得更好的攻击性能。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112225469.png width=2070 height=536 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112225469_hu_d6004b51c0051221.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112225469_hu_4e4d044ae18fcb03.png 1024w" loading=lazy alt="生成回归网络攻击性能 - CBR" class=gallery-image data-flex-grow=386 data-flex-basis=926px></p><p>作者还将CBR度量用于评估RF模型上的GRNA，同样效果也比随机猜测方法优秀。</p><h3 id=需要预测的样本数对生成回归网络攻击的影响><a href=#%e9%9c%80%e8%a6%81%e9%a2%84%e6%b5%8b%e7%9a%84%e6%a0%b7%e6%9c%ac%e6%95%b0%e5%af%b9%e7%94%9f%e6%88%90%e5%9b%9e%e5%bd%92%e7%bd%91%e7%bb%9c%e6%94%bb%e5%87%bb%e7%9a%84%e5%bd%b1%e5%93%8d class=header-anchor></a>需要预测的样本数对生成回归网络攻击的影响</h3><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112521389.png width=2070 height=518 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112521389_hu_d161a8253ebb6245.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112521389_hu_c6cd7467f682b69b.png 1024w" loading=lazy alt=需要预测的样本数的影响 class=gallery-image data-flex-grow=399 data-flex-basis=959px></p><p>四个数据集上的趋势表明，预测数据集中的样本越多，对手可以获得的每个特征的MSE越少。 换句话说，对手可以长期积累更多的预测输出，以提高其攻击精度。</p><h3 id=数据相关性对生成回归网络攻击的影响><a href=#%e6%95%b0%e6%8d%ae%e7%9b%b8%e5%85%b3%e6%80%a7%e5%af%b9%e7%94%9f%e6%88%90%e5%9b%9e%e5%bd%92%e7%bd%91%e7%bb%9c%e6%94%bb%e5%87%bb%e7%9a%84%e5%bd%b1%e5%93%8d class=header-anchor></a>数据相关性对生成回归网络攻击的影响</h3><p>由于LR和RF模型的性能低于NN模型，作者推断是因为一小部分推断出的特征值与真实相差甚远，导致整体攻击性能相对较低，于是作者研究数据相关性的影响。</p><p>数据相关性定义如下：</p>$$\begin{aligned}
\operatorname{corr}\left(x\_{\mathrm{adv}}, x\_{\mathrm{target}, i}\right) & =\frac{1}{d\_{\mathrm{adv}}} \sum\_{j=1}^{d\_{\mathrm{adv}}} a b s\left(r\left(x\_{\mathrm{adv}, j}, x\_{\mathrm{target}, i}\right)\right), \\\\
\operatorname{corr}\left(v, x\_{\mathrm{target}, i}\right) & =\frac{1}{c} \sum\_{j=1}^{c} a b s\left(r\left(v\_{j}, x\_{\mathrm{target}, i}\right)\right),
\end{aligned}$$<p>其中$r(a,b)$表示a和b之间的皮尔逊相关系数，$abs(\cdot)$表示绝对值。 本质上，两个系数越大，对手越容易通过生成回归网络攻击学习特征相关性。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112750781.png width=1747 height=769 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112750781_hu_8ebf89399dd41d2d.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103112750781_hu_b3faf008127ffd2d.png 1024w" loading=lazy alt=数据相关性对生成回归网络攻击性能 class=gallery-image data-flex-grow=227 data-flex-basis=545px></p><p>我们可以观察到相关系数$x_{adv}$和$v$都会影响生成回归网络攻击的攻击性能。$x_{target}$，$i$与$x_{adv}$和$v$之间较弱的相关性导致较低的推断准确度，例如图10a中的特征1和3以及图10b中的特征4和6。</p><h2 id=对策><a href=#%e5%af%b9%e7%ad%96 class=header-anchor></a>对策</h2><p>作者讨论了几种可能减轻所提出的特征推断攻击的潜在防御方法。</p><p><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103120035515.png width=2030 height=1174 srcset="/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103120035515_hu_3ad02ff2a52f490f.png 480w, /p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/IMAGE/image-20230103120035515_hu_843f72228808122a.png 1024w" loading=lazy alt=防御方法比较 class=gallery-image data-flex-grow=172 data-flex-basis=414px></p><div class=table-wrapper><table><thead><tr><th>策略名称</th><th>效果</th></tr></thead><tbody><tr><td>Rounding confidence scores</td><td>等式求解攻击有效，但生成回归网络攻击效果甚微</td></tr><tr><td>Dropout for neural networks model</td><td>有效，但攻击者还是有一个很好的推断</td></tr><tr><td>Pre-processing before collaboration</td><td>未做测试</td></tr><tr><td>Post-processing for verification</td><td>导致模型预测计算的巨大开销</td></tr><tr><td>Hide the vertical FL model</td><td>可能会导致新的隐私泄露</td></tr><tr><td>Differential Privacy (DP)</td><td>不适用</td></tr></tbody></table></div><h2 id=参考文章><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%ab%a0 class=header-anchor></a>参考文章</h2><ul><li><a class=link href=https://www.cnblogs.com/linear345/p/16406051.html target=_blank rel=noopener>【论文阅读】Feature Inference Attack on Model Predictions in Vertical Federated Learning - linear345 - 博客园 (cnblogs.com)</a></li><li><a class=link href=https://zhuanlan.zhihu.com/p/547510858 target=_blank rel=noopener>纵向联邦学习VFL 属性推理攻击 Feature inference attack on model predictions in VFL (ICDE21） - 知乎 (zhihu.com)</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/>联邦学习</a>
<a href=/tags/%E6%8E%A8%E7%90%86%E6%94%BB%E5%87%BB/>推理攻击</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/promptcare/><div class=article-image><img src=/p/promptcare/134905264_p11.cc464535343540ba9b38b0fe412207c8.webp width=5333 height=3000 loading=lazy alt="Featured image of post PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification" data-key=PromptCARE data-hash="md5-zEZFNTQ1QLqbOLD+QSIHyA=="></div><div class=article-details><h2 class=article-title>PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification</h2></div></a></article><article class=has-image><a href=/p/backdoor-defense-via-deconfounded-representation-learning/><div class=article-image><img src=/p/backdoor-defense-via-deconfounded-representation-learning/117158168.4a3979e605eab2be6fa626787f45f055.webp width=1300 height=731 loading=lazy alt="Featured image of post Backdoor Defense via Deconfounded Representation Learning" data-hash="md5-Sjl55gXqsr5vpiZ4f0XwVQ=="></div><div class=article-details><h2 class=article-title>Backdoor Defense via Deconfounded Representation Learning</h2></div></a></article><article class=has-image><a href=/p/graph-unlearning/><div class=article-image><img src=/p/graph-unlearning/110091745.beb76e913019c018b67066c59dbdb927.webp width=1787 height=1200 loading=lazy alt="Featured image of post Graph Unlearning" data-hash="md5-vrdukTAZwBi2cGbFnb25Jw=="></div><div class=article-details><h2 class=article-title>Graph Unlearning</h2></div></a></article><article class=has-image><a href=/p/apmsa-adversarial-perturbation-against-model-stealing-attacks/><div class=article-image><img src=/p/apmsa-adversarial-perturbation-against-model-stealing-attacks/108529802.ca7a4e4f5b98b46fa542961b7921bea3.webp width=1778 height=1000 loading=lazy alt="Featured image of post APMSA: Adversarial Perturbation Against Model Stealing Attacks" data-hash="md5-ynpOT1uYtG+lQpYbeSG+ow=="></div><div class=article-details><h2 class=article-title>APMSA: Adversarial Perturbation Against Model Stealing Attacks</h2></div></a></article></div></div></aside><link href=//unpkg.com/@waline/client@v3/dist/waline.css rel=stylesheet><div id=waline class=waline-container></div><style>.waline-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding);--waline-font-size:var(--article-font-size)}.waline-container .wl-count{color:var(--card-text-color-main)}</style><script type=module>
    import { init } from 'https://unpkg.com/@waline/client@v3/dist/waline.js';

    setTimeout(function () {
        
        init({"dark":"html[data-scheme=\"dark\"]","el":"#waline","emoji":["https://unpkg.com/@waline/emojis@1.2.0/weibo"],"lang":"zh-CN","locale":{"admin":"Admin","placeholder":null},"requiredMeta":["name","email","url"],"serverURL":"https://waline.lbqaq.top/"});
    }, 300);


</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 luoboQAQ</section><section class=powerby><a href=https://beian.miit.gov.cn>苏ICP备2021037116号</a><br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://npm.elemecdn.com/node-vibrant@latest/dist/vibrant.min.js crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e);const t=document.createElement("link");t.href="https://cdn.jsdelivr.net/npm/@callmebill/lxgw-wenkai-web@latest/style.css",t.type="text/css",t.rel="stylesheet",document.head.appendChild(t)})()</script></body></html>