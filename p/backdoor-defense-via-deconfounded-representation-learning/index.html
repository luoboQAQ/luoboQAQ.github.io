<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="《通过去边界表征学习进行后门防御》阅读笔记"><title>Backdoor Defense via Deconfounded Representation Learning</title><link rel=canonical href=https://lbqaq.top/p/backdoor-defense-via-deconfounded-representation-learning/><link rel=stylesheet href=/scss/style.min.ae1eb7f887336befbb146467b4baee8138bb2b0004f1f7aa9fcf3b40efa7e299.css><meta property='og:title' content="Backdoor Defense via Deconfounded Representation Learning"><meta property='og:description' content="《通过去边界表征学习进行后门防御》阅读笔记"><meta property='og:url' content='https://lbqaq.top/p/backdoor-defense-via-deconfounded-representation-learning/'><meta property='og:site_name' content='luoboQAQ'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='因果推理'><meta property='article:tag' content='DNN'><meta property='article:published_time' content='2024-05-07T14:30:00+08:00'><meta property='article:modified_time' content='2024-05-07T14:30:00+08:00'><meta property='og:image' content='https://lbqaq.top/p/backdoor-defense-via-deconfounded-representation-learning/117158168.webp'><meta name=twitter:title content="Backdoor Defense via Deconfounded Representation Learning"><meta name=twitter:description content="《通过去边界表征学习进行后门防御》阅读笔记"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://lbqaq.top/p/backdoor-defense-via-deconfounded-representation-learning/117158168.webp'><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><style>:root{--sys-font-family:-apple-system, "LXGW WenKai", 'Microsoft Yahei', 'WenQuanYi Micro Hei', sans-serif;--code-font-family:"JetBrains Mono", "LXGW WenKai Mono", Menlo, Monaco, Consolas, monospace;--article-font-family:"LXGW WenKai", sans-serif;--base-font-family:"LXGW WenKai", var(--sys-font-family), sans-serif}</style><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","smhd51txrk")</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/Mint_hu_90cbcbb19cfdb02a.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🌞</span></figure><div class=site-meta><h1 class=site-name><a href=/>luoboQAQ</a></h1><h2 class=site-description>快乐学习每一天</h2></div></header><ol class=menu-social><li><a href=https://github.com/luoboQAQ target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://lbqaq.top/index.xml target=_blank title=RSS订阅 rel=me><svg class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li><li><a href=https://pan.lbqaq.top target=_blank title=我的个人云盘 rel=me><svg class="icon icon-tabler icon-tabler-cloud" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M7 18a4.6 4.4.0 010-9 5 4.5.0 0111 2h1a3.5 3.5.0 010 7H7"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>文章</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>查询</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>友链</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#介绍>介绍</a></li><li><a href=#问题构造>问题构造</a><ol><li><a href=#因果分析>因果分析</a></li></ol></li><li><a href=#基于因果推理的后门防御>基于因果推理的后门防御</a><ol><li><a href=#后门模型训练>后门模型训练</a></li><li><a href=#干净模型训练>干净模型训练</a></li></ol></li><li><a href=#实验>实验</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/backdoor-defense-via-deconfounded-representation-learning/><img src=/p/backdoor-defense-via-deconfounded-representation-learning/117158168.webp width=1300 height=731 loading=lazy alt="Featured image of post Backdoor Defense via Deconfounded Representation Learning"></a></div><div class=article-details><header class=article-category><a href=/categories/%E8%AE%BA%E6%96%87/>论文</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/backdoor-defense-via-deconfounded-representation-learning/>Backdoor Defense via Deconfounded Representation Learning</a></h2><h3 class=article-subtitle>《通过去边界表征学习进行后门防御》阅读笔记</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2024-05-07</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 9 分钟</time></div></footer></div></header><section class=article-content><h2 id=介绍><a href=#%e4%bb%8b%e7%bb%8d class=header-anchor></a>介绍</h2><p>最近的研究表明，深度神经网络 （DNN） 容易受到后门攻击，攻击者通过毒害一些训练数据将隐蔽的后门注入 DNN。具体来说，后门攻击者将后门触发器（即特定模式）附加到一些良性训练数据，并将其标签更改为攻击者指定的目标标签。触发模式和目标标签之间的相关性将由 DNN 在训练期间学习。在推理过程中，后门模型在良性数据上表现正常，而当后门被激活时，其预测会被恶意改变。</p><p>相反，人类认知系统能够抵抗输入的扰动，例如后门攻击引起的隐蔽触发模式。这是因为人类对因果关系的敏感度高于干扰因素的关联。相比之下，经过训练以拟合中毒数据集的深度学习模型很难区分后门攻击带来的因果关系和统计关联。通过因果推理，我们可以识别因果关系并建立鲁棒的深度学习模型。因此，必须利用因果推理来分析和减轻后门攻击的威胁。</p><p>那么。什么是因果推理呢？因果推断在统计研究中有着悠久的历史。因果推理的目标是分析变量之间的因果效应，并减轻虚假相关性。</p><p>作者专注于图像分类任务，目标是在没有额外干净数据的情况下，在含有毒数据的数据集上训练出无后门的模型。作者首先构建了一个因果图来模拟后门数据的生成过程，特别考虑了干扰因素，即后门触发模式。借助因果图，发现后门攻击扮演了混杂因素的角色，并在输入图像与预测标签之间建立了一条虚假的联系。一旦深度神经网络学习了这种虚假联系，当附加了触发器时，它们的预测就会发生改变，转向目标标签。</p><p><img src=/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240505113806496.png width=981 height=449 srcset="/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240505113806496_hu_8635af4f5014bd4c.png 480w, /p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240505113806496_hu_a28f3ebe4682bdb6.png 1024w" loading=lazy alt=后门攻击因果图 class=gallery-image data-flex-grow=218 data-flex-basis=524px></p><p>作者在因果洞察的启发下，提出了一种新的后门防御方法，称为因果关系启发的后门防御（Causalityinspired Backdoor Defense，CBD），旨在学习去混淆的分类表示。由于后门攻击隐蔽且难以直接测量，无法通过因果推理直接阻断后门路径。受到解缠绕表征学习最新进展的启发，作者的目标是学习一种表征，它只保留与因果关系相关的信息。在CBD中，作者训练了两个深度神经网络（DNN）：一个专注于捕获虚假相关性，另一个专注于识别因果效应。第一个DNN通过提前停止策略有意地学习后门相关性。接着，我们通过最小化互信息训练第二个干净的模型，使其在隐藏空间中独立于第一个模型。训练完成后，只有干净的模型被用于下游的分类任务。</p><h2 id=问题构造><a href=#%e9%97%ae%e9%a2%98%e6%9e%84%e9%80%a0 class=header-anchor></a>问题构造</h2><p>作者假设攻击者已经预先生成了一组后门示例，并成功地将它们注入到训练数据集中。同时，作者假设防御者能够完全控制训练过程，但对数据集中后门示例的分布或比例一无所知。防御者的目标是训练出一个在中毒数据集上表现良好且无后门的模型，其性能应与在纯干净数据上训练的模型相当。一句话总结，就是在后门数据集上训练出一个干净模型。</p><h3 id=因果分析><a href=#%e5%9b%a0%e6%9e%9c%e5%88%86%e6%9e%90 class=header-anchor></a>因果分析</h3><p>因果推理的优越性在于它使人类能够识别因果关系，同时忽略任务中的非必要因素。相比之下，深度神经网络通常无法区分因果关系和统计关联，并且倾向于学习那些“更容易”的相关性，而不是必要的信息。这种走捷径的解决方案可能导致对无关因素（例如触发模式）的过度拟合，从而增加了后门攻击的脆弱性。因此，作者利用因果推理来分析DNN模型的训练过程，并降低后门注入的风险。</p><p>作者通过构建因果图$G$来模拟中毒数据的生成过程。在因果图中，作者使用节点来表示抽象数据变量，其中$X$代表输入图像，$Y$代表标签，$B$代表后门攻击。有向链接则表示这些变量之间的关系。除了$X$对$Y$的因果效应（$X → Y$）之外，后门攻击者可以通过将触发模式附加到图像（$B → X$）并将标签更改为目标标签（$B → Y$）来实施攻击。因此，后门攻击 $B$ 作为 $X$ 和 $Y$ 之间的混杂因素，打开了虚假路径 $X ← B → Y$（其中 $B = 1$ 表示图像中毒，$B = 0$ 表示图像干净）。我们所说的“虚假”路径是指这条路径位于 $X$ 到 $Y$ 的直接因果路径之外，它使得 $X$ 和 $Y$ 之间产生了虚假的相关性，并在触发器被激活时导致错误的效果。深度神经网络（DNN）很难区分虚假相关性和因果关系。因此，如果在可能中毒的数据集上直接训练 DNN，模型将面临被后门攻击的风险。</p><p>为了探究 $X$ 对 $Y$ 的因果效应，研究者通常使用 do 演算在因果干预中进行后门调整：$P(Y|do(X)) = \sum_{B\in\{0,1\}}P(Y|X,B)P(B)$。然而，在作者的设置中，由于混杂变量 $B$ 几乎无法被检测和测量，不能简单地使用后门调整来阻断后门路径。相反，由于大多数深度学习模型的目标是学习下游任务的准确嵌入表示，所以目标是解开隐藏空间中的混淆效应和因果效应。</p><h2 id=基于因果推理的后门防御><a href=#%e5%9f%ba%e4%ba%8e%e5%9b%a0%e6%9e%9c%e6%8e%a8%e7%90%86%e7%9a%84%e5%90%8e%e9%97%a8%e9%98%b2%e5%be%a1 class=header-anchor></a>基于因果推理的后门防御</h2><p>在现实应用中，直接识别数据空间中 $X$ 的混杂因素和因果因素可能相当困难。作者假设这些混杂因素和因果因素会在隐藏的表征中得到体现。通常，训练包括两个 DNN，即 $f_B$ 和 $f_C$，它们分别专注于捕获虚假相关性和因果关系。作者从 $f_B$ 和 $f_C$ 的倒数第二层提取嵌入向量，分别表示为 $R$ 和 $Z$。为了避免混淆，本文中使用大写字母表示变量，小写字母表示具体值。为了生成能够捕获因果关系的高质量变量 $Z$，作者在训练阶段，首先在中毒数据集上训练 $f_B$，以捕捉后门的虚假相关性。随后，训练另一个干净的模型 $f_C$，鼓励其在隐藏空间（即 $Z$ 与 $R$ 独立）中的独立性，并通过最小化互信息和实施样本重新加权策略。训练完成后，只有 $f_C$ 被用于下游的分类任务。</p><p><img src=/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240506143306646.png width=855 height=416 srcset="/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240506143306646_hu_223138b87ac4fbd.png 480w, /p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240506143306646_hu_78af587a89ae9b69.png 1024w" loading=lazy alt=框架图 class=gallery-image data-flex-grow=205 data-flex-basis=493px></p><h3 id=后门模型训练><a href=#%e5%90%8e%e9%97%a8%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83 class=header-anchor></a>后门模型训练</h3><p>首先，作者在具有交叉熵损失的毒数据集上训练 $f_B$，目的是捕获后门的虚假相关性。由于中毒数据仍然包含因果关系，作者有意通过早期停止策略来增强 $f_B$ 中的混杂偏差。具体来说，作者只对 $f_B$ 进行了少数几个时期的训练（例如，5 个时期），并在训练 $f_C$ 时冻结了其参数。这是因为先前的研究表明，后门关联比因果关系更容易被学习。</p><h3 id=干净模型训练><a href=#%e5%b9%b2%e5%87%80%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83 class=header-anchor></a>干净模型训练</h3><p>作者提出了具有信息瓶颈和互信息最小化的训练目标：</p>$$\mathcal{L}_C=\min\underbrace{\beta I(Z;X)}_{1}-\underbrace{I(Z;Y)}_{2}+\underbrace{I(Z;R)}_{3}$$<p>其中$I(.;.)$​表示互信息</p><ul><li>①用来限制来自输入的不相关信息</li><li>②用来捕获变量 $Z$​ 用于标签预测的核心信息</li><li>③描述了后门嵌入 $R$ 和去混淆嵌入 $Z$ 之间的依赖程度。它鼓励 $Z$ 独立于 $R$，通过最小化互信息来关注因果效应</li></ul><blockquote><p><strong>互信息</strong></p><p><strong>互信息</strong>（mutual Information，MI）度量了两个变量之间相互依赖的程度。具体来说，对于两个随机变量，MI是一个随机变量由于已知另一个随机变量而减少的“信息量”（单位通常为比特）。</p>$$I(X;Y)=D_{\mathrm{KL}}(p(x,y)\|p(x)\otimes p(y))$$<p>直观上，互信息度量 <em>X</em> 和 <em>Y</em> 共享的信息：它度量知道这两个变量其中一个，对另一个不确定度减少的程度。例如，如果 <em>X</em> 和 <em>Y</em> 相互独立，则知道 <em>X</em> 不对 <em>Y</em> 提供任何信息，反之亦然，所以它们的互信息为零。在另一个极端，如果 <em>X</em> 是 <em>Y</em> 的一个确定性函数，且 <em>Y</em> 也是 <em>X</em> 的一个确定性函数，那么传递的所有信息被 <em>X</em> 和 <em>Y</em> 共享：知道 <em>X</em> 决定 <em>Y</em> 的值，反之亦然。</p></blockquote><p>然而，上述的公式并不能直接求解，为此，作者放宽了限制。</p><p><strong>公式1</strong></p>$$\begin{aligned}
I(Z;X)& =\sum_x\sum_zp(z,x)\mathrm{log}\frac{p(z,x)}{p(z)p(x)} \\
&=\sum_x\sum_zp(z|x)p(x)\mathrm{log}\frac{p(z|x)p(x)}{p(z)p(x)} \\
&=\sum_x\sum_zp(z|x)p(x)\mathrm{log~}p(z|x)-\sum_zp(z)\mathrm{log~}p(z)
\end{aligned}$$<p>然而，边际概率$p(z)=\sum_xp(z|x)p(x)$在实践中很难计算，为此作者通过变分分布$q(z)$来近似$p(z)$，由于KL散度是非负的，根据吉布斯不等式：$D_{\mathrm{KL}}(p(z)||q(z)) \geq 0 \Rightarrow -\sum_zp(z)\mathrm{log~}p(z)\leq-\sum_zp(z)\mathrm{log~}q(z)$</p><p>将其代入上式：</p>$$\begin{aligned}
I(Z;X)& \leq\sum_xp(x)\sum_zp(z|x)\mathrm{log~}p(z|x)-\sum_zp(z)\mathrm{log~}q(z) \\
&=\sum_xp(x)\sum_zp(z|x)\mathrm{log}\frac{p(z|x)}{q(z)} \\
&=\sum_xp(x)D_{\mathrm{KL}}(p(z|x)||q(z))
\end{aligned}$$<p>作者假设$p(z|x)=\mathcal{N}(\mu(x),\mathrm{diag}\{\sigma^2(x)\})$是高斯分布，其中$\mu(x)$是$x$的编码嵌入，$\mathrm{diag}\{\sigma^2(x)\}=\{\sigma_d^2\}_{d=1}^D$表示方差的对角矩阵，并假设$q(z)=\mathcal{N}(0,I)$，于是上式就可以改写成：</p>$$D_{\mathrm{KL}}(p(z|x)||q(z))=\frac{1}{2}||\mu(x)||_2^2+\frac{1}{2}\sum_d(\sigma_d^2-\mathrm{log}\sigma_d^2-1)$$<p>为了便于优化作者将$\sigma(x)$定义为全零矩阵，所以$z=\mu(x)$成为确定性嵌入。</p><p>最后推导出来，公式一就相当于直接在嵌入向量 $z$ 上应用L2正则化</p><p><strong>公式2</strong></p><p>根据互信息的定义，有$I(Z;Y)=H(Y)-H(Y|Z)$，其中$H(·)$ 和 $H(·|·)$ 分别表示熵和条件熵。由于$H(Y)$ 是一个正常数，可以忽略不计，因此有以下不等式：</p>$$-I(Z;Y)\leq H(Y|Z)$$<p>在实验中，$H(Y|Z)$可以计算并优化为交叉熵损失。为了进一步鼓励 $f_C$ 和 $f_B$ 之间的独立性，作者固定了 $f_B$ 的参数，并使用样本加权交叉熵损失来训练 $f_C$，权重的计算公式为：</p>$$w(x)=\frac{CE(f_B(x),y)}{CE(f_B(x),y)+CE(f_C(x),y)}$$<p>对于 $f_B$上损失较大的样本，$w(x)$接近1;而当损失非常小时，$w(x)$接近 0。从而让 $f_C$专注于 $f_B$的“难”示例，以鼓励其独立性。</p><p><strong>公式3</strong></p><p>基于互信息和KL散度的关系，有$I(Z;R)=D_{\mathrm{KL}}(p(Z,R)||p(Z)p(R))$，即$I(Z;R)$等价于联合分布$p(Z,R)$和两个边际$p(Z)p(R)$的乘积之间的KL散度。</p><p>为了最小化混杂惩罚项，作者采用了对抗学习。判别器$D_\phi$被训练成将联合分布$p(Z,R)$分类为1，将边际分布$p(Z)p(R)$分类为0。边际分布$p(Z)p(R)$的样本是通过对$p(Z,R)$训练批次中样本$(z,r)$的单个表示进行shuffle而获得的。优化函数如下：</p>$$\mathcal{L}_{adv}=\min_{\theta_C}\max_\phi\mathbb{E}_{p(z,r)}[D_\phi(z,r)]-\mathbb{E}_{p(z)p(r)}[D_\phi(z,r)]$$<p>其中$\theta_C$ 和$\phi$分别表示 $f_C$ 和 $D_\phi$ 的参数。</p><p>综上，$f_C$的损失函数为：</p>$$\mathcal{L}_C=\mathcal{L}_{wce}+\mathcal{L}_{adv}+\beta||\mu(x)||_2^2$$<p>​</p><p>算法的伪代码如下：</p><p><img src=/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240506164026425.png width=989 height=662 srcset="/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240506164026425_hu_934445f40a309d99.png 480w, /p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240506164026425_hu_83565e92195510bf.png 1024w" loading=lazy alt=CBD算法 class=gallery-image data-flex-grow=149 data-flex-basis=358px></p><h2 id=实验><a href=#%e5%ae%9e%e9%aa%8c class=header-anchor></a>实验</h2><p><strong>数据集和模型</strong></p><ul><li>CIFAR-10：WideResNet</li><li>GTSRB：WideResNet</li><li>ImageNet：ResNet-34</li></ul><p><strong>攻击基线</strong></p><p>BadNets、Trojan attack、Blend attack、Sinusoidal signal attack (SIG)、Dynamic attack、WaNet</p><p><strong>防御基线</strong></p><p>Fine-pruning (FP) 、Mode Connectivity Repair (MCR) 、 Neural Attention Distillation (NAD) 、 Anti-Backdoor Learning (ABL) 、Decoupling-based backdoor defense (DBD)</p><p>作者在<strong>10%中毒率</strong>下和其他防御方法进行了对比，证明了该方法的有效性。</p><p><img src=/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507124654213.png width=1700 height=1262 srcset="/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507124654213_hu_e22381df4b51cf71.png 480w, /p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507124654213_hu_f1aaa1291e8bdfdc.png 1024w" loading=lazy alt=实验 class=gallery-image data-flex-grow=134 data-flex-basis=323px></p><p>同时，作者也考虑了<strong>不同中毒率</strong>下防御方法的有效性</p><p><img src=/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507124825684.png width=1094 height=593 srcset="/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507124825684_hu_8c44ae762888829f.png 480w, /p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507124825684_hu_4b83798a9ef554aa.png 1024w" loading=lazy alt=不同中毒率 class=gallery-image data-flex-grow=184 data-flex-basis=442px></p><p>此外，作者还绘制了t-SNE图，从a和b可以看出在训练后，混杂成分$r$和因果成分$z$之间存在明显的分离。从c和d中可以看出，中毒样本的嵌入在$r$中形成簇，这表明已经学习了后门触发器和目标标签之间的虚假相关性。相比之下，中毒样本与样本密切相关，其真实标签位于去混淆嵌入$z$中，这表明CBD可以有效地防御后门攻击。</p><p><img src=/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507125037327.png width=1948 height=593 srcset="/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507125037327_hu_37a257ce2dde5951.png 480w, /p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507125037327_hu_d2f1c5d5b749b3e3.png 1024w" loading=lazy alt=t-SNE class=gallery-image data-flex-grow=328 data-flex-basis=788px></p><p>作者最后还计算了防御所需的时间，可见防御并不需要更多额外的时间</p><p><img src=/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507125439316.png width=912 height=281 srcset="/p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507125439316_hu_a93b7ee3849f4cbe.png 480w, /p/backdoor-defense-via-deconfounded-representation-learning/IMAGE/image-20240507125439316_hu_a9d05e324970c33d.png 1024w" loading=lazy alt=运算时间 class=gallery-image data-flex-grow=324 data-flex-basis=778px></p></section><footer class=article-footer><section class=article-tags><a href=/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E7%90%86/>因果推理</a>
<a href=/tags/dnn/>DNN</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/promptcare/><div class=article-image><img src=/p/promptcare/134905264_p11.cc464535343540ba9b38b0fe412207c8.webp width=5333 height=3000 loading=lazy alt="Featured image of post PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification" data-key=PromptCARE data-hash="md5-zEZFNTQ1QLqbOLD+QSIHyA=="></div><div class=article-details><h2 class=article-title>PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification</h2></div></a></article><article class=has-image><a href=/p/graph-unlearning/><div class=article-image><img src=/p/graph-unlearning/110091745.beb76e913019c018b67066c59dbdb927.webp width=1787 height=1200 loading=lazy alt="Featured image of post Graph Unlearning" data-hash="md5-vrdukTAZwBi2cGbFnb25Jw=="></div><div class=article-details><h2 class=article-title>Graph Unlearning</h2></div></a></article><article class=has-image><a href=/p/apmsa-adversarial-perturbation-against-model-stealing-attacks/><div class=article-image><img src=/p/apmsa-adversarial-perturbation-against-model-stealing-attacks/108529802.ca7a4e4f5b98b46fa542961b7921bea3.webp width=1778 height=1000 loading=lazy alt="Featured image of post APMSA: Adversarial Perturbation Against Model Stealing Attacks" data-hash="md5-ynpOT1uYtG+lQpYbeSG+ow=="></div><div class=article-details><h2 class=article-title>APMSA: Adversarial Perturbation Against Model Stealing Attacks</h2></div></a></article><article class=has-image><a href=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/><div class=article-image><img src=/p/feature-inference-attack-on-model-predictions-in-vertical-federated-learning/100018879.3b7b76e6de45f5dbdd3bd31b20aa6bae.webp width=2833 height=1814 loading=lazy alt="Featured image of post Feature Inference Attack on Model Predictions in Vertical Federated Learning" data-hash="md5-O3t25t5F9dvdO9MbIKprrg=="></div><div class=article-details><h2 class=article-title>Feature Inference Attack on Model Predictions in Vertical Federated Learning</h2></div></a></article></div></div></aside><link href=//unpkg.com/@waline/client@v3/dist/waline.css rel=stylesheet><div id=waline class=waline-container></div><style>.waline-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding);--waline-font-size:var(--article-font-size)}.waline-container .wl-count{color:var(--card-text-color-main)}</style><script type=module>
    import { init } from 'https://unpkg.com/@waline/client@v3/dist/waline.js';

    setTimeout(function () {
        
        init({"dark":"html[data-scheme=\"dark\"]","el":"#waline","emoji":["https://unpkg.com/@waline/emojis@1.2.0/weibo"],"lang":"zh-CN","locale":{"admin":"Admin","placeholder":null},"requiredMeta":["name","email","url"],"serverURL":"https://waline.lbqaq.top/"});
    }, 300);


</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 luoboQAQ</section><section class=powerby><a href=https://beian.miit.gov.cn>苏ICP备2021037116号</a><br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://npm.elemecdn.com/node-vibrant@latest/dist/vibrant.min.js crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e);const t=document.createElement("link");t.href="https://cdn.jsdelivr.net/npm/@callmebill/lxgw-wenkai-web@latest/style.css",t.type="text/css",t.rel="stylesheet",document.head.appendChild(t)})()</script></body></html>