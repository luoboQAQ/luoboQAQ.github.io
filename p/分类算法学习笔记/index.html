<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="数据挖掘中分类算法的学习笔记"><title>分类算法学习笔记</title><link rel=canonical href=https://lbqaq.top/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/><link rel=stylesheet href=/scss/style.min.ae1eb7f887336befbb146467b4baee8138bb2b0004f1f7aa9fcf3b40efa7e299.css><meta property='og:title' content="分类算法学习笔记"><meta property='og:description' content="数据挖掘中分类算法的学习笔记"><meta property='og:url' content='https://lbqaq.top/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/'><meta property='og:site_name' content='luoboQAQ'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='数据挖掘'><meta property='article:tag' content='交叉验证'><meta property='article:tag' content='SVM'><meta property='article:published_time' content='2022-05-10T14:00:16+08:00'><meta property='article:modified_time' content='2022-05-10T14:00:16+08:00'><meta property='og:image' content='https://lbqaq.top/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/86368113.webp'><meta name=twitter:title content="分类算法学习笔记"><meta name=twitter:description content="数据挖掘中分类算法的学习笔记"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://lbqaq.top/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/86368113.webp'><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><style>:root{--sys-font-family:-apple-system, "LXGW WenKai", 'Microsoft Yahei', 'WenQuanYi Micro Hei', sans-serif;--code-font-family:"JetBrains Mono", "LXGW WenKai Mono", Menlo, Monaco, Consolas, monospace;--article-font-family:"LXGW WenKai", sans-serif;--base-font-family:"LXGW WenKai", var(--sys-font-family), sans-serif}</style><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","smhd51txrk")</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/Mint_hu_90cbcbb19cfdb02a.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🌞</span></figure><div class=site-meta><h1 class=site-name><a href=/>luoboQAQ</a></h1><h2 class=site-description>快乐学习每一天</h2></div></header><ol class=menu-social><li><a href=https://github.com/luoboQAQ target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://lbqaq.top/index.xml target=_blank title=RSS订阅 rel=me><svg class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li><li><a href=https://pan.lbqaq.top target=_blank title=我的个人云盘 rel=me><svg class="icon icon-tabler icon-tabler-cloud" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M7 18a4.6 4.4.0 010-9 5 4.5.0 0111 2h1a3.5 3.5.0 010 7H7"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>文章</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>查询</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>友链</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#分类算法的作用>分类算法的作用</a></li><li><a href=#交叉验证>交叉验证</a><ol><li><a href=#基本思想>基本思想</a></li><li><a href=#k折交叉验证k-fold-cross-validation>K折交叉验证(K-fold cross-validation)</a></li></ol></li><li><a href=#支持向量机svm>支持向量机(SVM)</a><ol><li><a href=#基本思想-1>基本思想</a></li><li><a href=#支持向量>支持向量</a></li><li><a href=#svm模型目标函数>SVM模型目标函数</a></li><li><a href=#kkt条件>KKT条件</a></li><li><a href=#svm对偶性>SVM对偶性</a></li></ol></li><li><a href=#svm核kernel方法>SVM核（Kernel）方法</a><ol><li><a href=#基本概念>基本概念</a></li><li><a href=#线性核函数linear-kernel>线性核函数（Linear Kernel）</a></li><li><a href=#多项式核函数polynomial-kernel>多项式核函数（Polynomial Kernel）</a></li><li><a href=#高斯核函数gaussian-kernel>高斯核函数（Gaussian Kernel）</a></li><li><a href=#sigmoid核函数>Sigmoid核函数</a></li></ol></li><li><a href=#svm软间隔>SVM软间隔</a></li><li><a href=#svm编程实现>SVM编程实现</a></li><li><a href=#svm实现多分类>SVM实现多分类</a><ol><li><a href=#一对多法ovr>一对多法（OVR）</a></li><li><a href=#一对一法ovo>一对一法（OVO）</a></li></ol></li><li><a href=#参考资料>参考资料</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/86368113.webp width=3893 height=2500 loading=lazy alt="Featured image of post 分类算法学习笔记"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/>数据挖掘</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>分类算法学习笔记</a></h2><h3 class=article-subtitle>数据挖掘中分类算法的学习笔记</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2022-05-10</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 11 分钟</time></div></footer></div></header><section class=article-content><h2 id=分类算法的作用><a href=#%e5%88%86%e7%b1%bb%e7%ae%97%e6%b3%95%e7%9a%84%e4%bd%9c%e7%94%a8 class=header-anchor></a>分类算法的作用</h2><p>分类是在一群已经知道类别标号的样本中，训练一种<strong>分类器</strong>，让其能够对某种未知的样本进行分类。分类算法属于一种有监督的学习。分类算法的分类过程就是建立一种分类模型来描述预定的数据集或概念集，通过分析由属性描述的数据库元组来构造模型。分类的目的就是使用分类对新的数据集进行划分，其主要涉及分类规则的准确性、过拟合、矛盾划分的取舍等。</p><ul><li><strong>有监督学习和无监督学习的区别</strong><ul><li>有监督学习是指数据集的正确输出已知情况下的一类学习算法。因为输入和输出已知，意味着输入和输出之间有一个关系，监督学习算法就是要发现和总结这种“关系”。</li><li>无监督学习是指对无标签数据的一类学习算法。因为没有标签信息，意味着需要从数据集中发现和总结模式或者结构。</li><li><strong>简单来说，是否有监督（supervised），就看输入数据是否有标签（label）</strong></li></ul></li></ul><h2 id=交叉验证><a href=#%e4%ba%a4%e5%8f%89%e9%aa%8c%e8%af%81 class=header-anchor></a>交叉验证</h2><h3 id=基本思想><a href=#%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3 class=header-anchor></a>基本思想</h3><p>交叉验证的基本思想是把在某种意义下将原始数据(dataset)进行分组，一部分做为训练集(train set)，另一部分做为验证集(validation set or test set)，首先用训练集对分类器进行训练，再利用验证集来测试训练得到的模型(model)，以此来做为评价分类器的性能指标。<strong>用交叉验证的目的是为了得到可靠稳定的模型</strong>。</p><h3 id=k折交叉验证k-fold-cross-validation><a href=#k%e6%8a%98%e4%ba%a4%e5%8f%89%e9%aa%8c%e8%af%81k-fold-cross-validation class=header-anchor></a>K折交叉验证(K-fold cross-validation)</h3><p>K折交叉验证就是进行多次train_test_split划分；每次划分时，在不同的数据集上进行训练、测试评估，从而得出一个评价结果；如果是10折交叉验证，意思就是在原始数据集上，进行10次划分，每次划分进行一次训练、评估，最后得到10次划分后的评估结果，一般在这几次评估结果上取平均得到最后的评分。<strong>其中，k一般取5或10。</strong></p><p><strong>K折交叉验证的步骤：</strong></p><ol><li>将原始数据集划分为相等的K部分（“折”）</li><li>将第1部分作为测试集，其余作为训练集</li><li>训练模型，计算模型在测试集上的准确率</li><li>每次用不同的部分作为测试集，重复步骤2和3 K次</li><li>将平均准确率作为最终的模型准确率</li></ol><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/1.png width=1102 height=639 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/1_hu_4681689a69ccb62e.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/1_hu_b1b12769f774e315.png 1024w" loading=lazy alt=10折交叉验证 class=gallery-image data-flex-grow=172 data-flex-basis=413px></p><blockquote><p>💡 要会给定数据集进行K折交叉验证
要会计算模型准确率（每次的准确率、最终的准确率）</p></blockquote><h2 id=支持向量机svm><a href=#%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f%e6%9c%basvm class=header-anchor></a>支持向量机(SVM)</h2><h3 id=基本思想-1><a href=#%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3-1 class=header-anchor></a>基本思想</h3><p>SVM学习的基本思想是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。</p><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/2.png width=922 height=812 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/2_hu_3687cbff79f1d427.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/2_hu_85686e0bccfa57fc.png 1024w" loading=lazy alt=SVM基本思想 class=gallery-image data-flex-grow=113 data-flex-basis=272px></p><p>用我自己的理解，就是找一条线将两个数据集分开，要保证这条线到两边的数据集距离最大。那么，如何才能保证距离最大呢，这就是下面要讨论的难点了。</p><h3 id=支持向量><a href=#%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f class=header-anchor></a>支持向量</h3><blockquote><p>在支持向量机中，距离超平面最近的且满足一定条件的几个训练样本点被称为支持向量。</p></blockquote><p>在上图中，处于虚线上的点（即红色的点）我们就将其定义为支持向量。那么，如何得到支持向量到超平面的距离呢？我们引入<strong>几何间隔</strong>的概念：</p>$$
\gamma = \frac{y(w^Tx + b)}{||w||_2} = \frac{\gamma^{'}}{||w||_2}
$$<p>一般我们都取函数间隔$\gamma^{&rsquo;}$为1，这样我们就可以得到支持向量到超平面的距离为$\frac{1}{||w||_2}$，两个支持向量之间的距离为$\frac{2}{||w||_2}$</p><h3 id=svm模型目标函数><a href=#svm%e6%a8%a1%e5%9e%8b%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0 class=header-anchor></a>SVM模型目标函数</h3><p>SVM的模型是让所有点到超平面的距离大于一定的距离，也就是所有的分类点要在各自类别的支持向量两边。用数学式子表示为：</p>$$
max \\;\\; \frac{1}{||w||_2} \\;\\; s.t \\;\\; y_i(w^Tx_i + b) \geq 1 (i =1,2,...m)
$$<p>其中，$||w||_2$为向量$w$的L2范数，即：</p>$$
||w||_2=\sqrt{w_1^2+w_2^2}
$$<p>为了去除根号方便计算，我们将原式转化为：</p>$$
min \\;\\; \frac{1}{2}||w||_2^2 \\;\\; s.t \\;\\; y_i(w^Tx_i + b) \geq 1 (i =1,2,...m)
$$<p>由于目标函数$\frac{1}{2}||w||_2^2$是凸函数，同时约束条件不等式是仿射的，根据凸优化理论，我们可以通过拉格朗日函数将我们的优化目标转化为无约束的优化函数。于是根据拉格朗日乘子法，我们得到：</p>$$
L(w,b,\alpha) = \frac{1}{2}||w||_2^2 - \sum \limits _{i=1}^{m} \alpha_i [y_i(w^Tx_i + b) - 1] \\; 满足\alpha_i \geq 0
$$<p>其中$\alpha_i$为拉格朗日乘子。</p><h3 id=kkt条件><a href=#kkt%e6%9d%a1%e4%bb%b6 class=header-anchor></a>KKT条件</h3><p>我们对上面的式子求偏导，可以得到</p>$$
\frac{\partial L }{\partial w}=0,\frac{\partial L }{\partial b}=0
$$<p>解得</p>$$
\boldsymbol{w}=\sum_{i=1}^N{\alpha_iy_i\boldsymbol{x}_{\boldsymbol{i}}}
$$$$
\sum_{i=1}^N{\alpha_iy_i}=0
$$<p>解方程可得</p>$$
\begin{cases}
\alpha_i\geq 0 \\\\
y_i(\overrightarrow{w_i}\cdot \overrightarrow{x_i}+b)-1\geq 0 \\\\
\alpha_i(y_i(\overrightarrow{w_i}\cdot\overrightarrow{x_i}+b)-1)=0
\end{cases}
$$<p>上面的式子即为KKT条件</p><h3 id=svm对偶性><a href=#svm%e5%af%b9%e5%81%b6%e6%80%a7 class=header-anchor></a>SVM对偶性</h3><p>现在我们令</p>$$
\theta \left( \boldsymbol{w} \right) =\underset{\alpha _{_i}\ge 0}{\max}\ L\left( \boldsymbol{w,}b,\boldsymbol{\alpha } \right)
$$<p>当样本点不满足约束条件时，即在可行解区域外$y_i\left(\boldsymbol{w}\cdot \boldsymbol{x}_{\boldsymbol{i}}+b\right)&lt;1$。此时，将$\alpha_i$设置为无穷大，则$\theta \left( \boldsymbol{w} \right)$也为无穷大。</p><p>当样本点不满足约束条件时，即在可行解区域内$y_i\left(\boldsymbol{w}\cdot \boldsymbol{x}_{\boldsymbol{i}}+b\right)\ge1$。此时，$\theta \left( \boldsymbol{w} \right)$为原函数本身。</p><p>于是，将两种情况合并起来就可以得到我们新的目标函数：</p>$$
\theta \left( \boldsymbol{w} \right) =\begin{cases} \frac{1}{2}\lVert \boldsymbol{w} \rVert ^2\ ,\boldsymbol{x}\in \text{可行区域}\\\\ +\infty \ \ \ \ \ ,\boldsymbol{x}\in \text{不可行区域}\\\\ \end{cases}
$$<p>于是原约束问题就等价于：</p>$$
\underset{\boldsymbol{w,}b}{\min}\ \theta \left( \boldsymbol{w} \right) =\underset{\boldsymbol{w,}b}{\min}\underset{\alpha _i\ge 0}{\max}\ L\left( \boldsymbol{w,}b,\boldsymbol{\alpha } \right)
$$<p>由上小节，我们可以知道该函数满足拉格朗日函数<strong>对偶性</strong>：</p><ul><li>优化问题是凸优化问题</li><li>满足KKT条件</li></ul><p>于是，我们可以将其最小和最大的位置交换一下，这样就变成了：</p>$$
\underset{\alpha _i\ge 0}{\max}\underset{\boldsymbol{w,}b}{\min}\ L\left( \boldsymbol{w,}b,\boldsymbol{\alpha } \right)
$$<p>从上式中，我们可以先求优化函数对于$w$和$b$的极小值。接着再求拉格朗日乘子$\alpha$的极大值。</p><p>通过在上节中由偏导推出的两个式子，我们得到了$w$和$\alpha$的关系，就可以带入优化函数$L(w,b,\alpha)$消去$w$了</p><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code1.png width=583 height=76 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code1_hu_cb82dee7ae24659e.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code1_hu_c187ca30af0efd45.png 1024w" loading=lazy class=gallery-image data-flex-grow=767 data-flex-basis=1841px></p><p>此时原式为</p><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code2.png width=457 height=76 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code2_hu_d251def9ea181a2.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code2_hu_7a23d688c46e7d21.png 1024w" loading=lazy class=gallery-image data-flex-grow=601 data-flex-basis=1443px></p><p>我们对目标式子加一个负号，将求解极大转换为求解极小</p><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code3.png width=422 height=76 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code3_hu_588c87eed60ed567.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/Code3_hu_6db0bce3cc74ddaa.png 1024w" loading=lazy class=gallery-image data-flex-grow=555 data-flex-basis=1332px></p><h2 id=svm核kernel方法><a href=#svm%e6%a0%b8kernel%e6%96%b9%e6%b3%95 class=header-anchor></a>SVM核（Kernel）方法</h2><h3 id=基本概念><a href=#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5 class=header-anchor></a>基本概念</h3><p>在上节我们推导出的式子中，我们可以看到上式低维特征仅仅以内积$x_i \bullet x_j$ 的形式出现，如果我们定义一个低维特征空间到高维特征空间的映射$T$，将所有特征映射到一个更高的维度，让数据线性可分，我们就可以求出分离超平面和分类决策函数了。</p><p>但是，将数据从低维映射到高维，将会大大增加计算的复杂度，如果遇到无穷维的情况，就根本无从计算了。这时，就需要引入<strong>核函数</strong>了。</p><p>我们定义果存在函数$K(x,z)$，对于任意$x, z$ ，都有：</p>$$
K(x, z) = T(x) \bullet T(z)
$$<p>那么我们就称$K(x, z)$为核函数。</p><p>通过核函数，就避免了在刚才我们提到了在高维维度空间计算内积的恐怖计算量。也就是说，我们可以好好享受在高维特征空间线性可分的红利，却避免了高维特征空间恐怖的内积计算量。</p><p>下面我们来看看常见的核函数, 选择这几个核函数介绍是因为scikit-learn中默认可选的就是下面几个核函数。</p><h3 id=线性核函数linear-kernel><a href=#%e7%ba%bf%e6%80%a7%e6%a0%b8%e5%87%bd%e6%95%b0linear-kernel class=header-anchor></a>线性核函数（Linear Kernel）</h3><p>其实就是线性可分SVM，表达式为：</p>$$
K(x, z) = x \bullet z
$$<p>也就是说，线性可分SVM我们可以和线性不可分SVM归为一类，区别仅仅在于线性可分SVM用的是线性核函数。</p><h3 id=多项式核函数polynomial-kernel><a href=#%e5%a4%9a%e9%a1%b9%e5%bc%8f%e6%a0%b8%e5%87%bd%e6%95%b0polynomial-kernel class=header-anchor></a>多项式核函数（Polynomial Kernel）</h3><p>多项式核函数是线性不可分SVM常用的核函数之一，表达式为：</p>$$
K(x, z) = （\gamma x \bullet z + r)^d
$$<p>其中，$\gamma, r,d$都需要自己调参定义。</p><h3 id=高斯核函数gaussian-kernel><a href=#%e9%ab%98%e6%96%af%e6%a0%b8%e5%87%bd%e6%95%b0gaussian-kernel class=header-anchor></a>高斯核函数（Gaussian Kernel）</h3><p>在SVM中也称为径向基核函数（Radial Basis Function,RBF），它是非线性分类SVM最主流的核函数。libsvm默认的核函数就是它。表达式为：</p>$$
K(x, z) = exp(-\gamma||x-z||^2)
$$<p>其中，$\gamma$大于0，需要自己调参定义。</p><blockquote><p>💡 高斯核函数很重要，一定要记住</p></blockquote><h3 id=sigmoid核函数><a href=#sigmoid%e6%a0%b8%e5%87%bd%e6%95%b0 class=header-anchor></a>Sigmoid核函数</h3><p>也是线性不可分SVM常用的核函数之一，表达式为：</p>$$
K(x, z) = tanh（\gamma x \bullet z + r)
$$<p>其中，$\gamma, r$都需要自己调参定义。</p><h2 id=svm软间隔><a href=#svm%e8%bd%af%e9%97%b4%e9%9a%94 class=header-anchor></a>SVM软间隔</h2><p>有时候本来数据的确是可分的，也就是说可以用 线性分类SVM的学习方法来求解，但是却因为混入了异常点，导致不能线性可分，比如下图</p><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/3.png width=300 height=245 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/3_hu_e4d495a9e40656e.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/3_hu_247b535caae0e6fd.png 1024w" loading=lazy alt=有异常点的数据 class=gallery-image data-flex-grow=122 data-flex-basis=293px></p><p>这种情况下，SVM引入了软间隔最大化的方法来解决。</p><p>SVM对训练集里面的每个样本$(x_i,y_i)$引入了一个松弛变量$\xi_i \geq 0$,使函数间隔加上松弛变量大于等于1，也就是说：</p>$$
y_i(w\bullet x_i +b) \geq 1- \xi_i
$$<p>对比硬间隔最大化，可以看到我们对样本到超平面的函数距离的要求放松了，之前是一定要大于等于1，现在只需要加上一个大于等于0的松弛变量能大于等于1就可以了。当然，松弛变量不能白加，这是有成本的，每一个松弛变量$\xi_i$, 对应了一个代价$\xi_i$，这个就得到了我们的软间隔最大化的SVM学习条件如下：</p>$$
min\\;\\; \frac{1}{2}||w||_2^2 +C\sum\limits{i=1}^{m}\xi_i
$$$$
s.t. \\;\\; y_i(w^Tx_i + b) \geq 1 - \xi_i \\;\\;(i =1,2,...m)
$$$$
\xi_i \geq 0 \\;\\;(i =1,2,...m)
$$<p>这里，$C>0$为惩罚参数，可以理解为我们一般回归和分类问题正则化时候的参数。$C$越大，对误分类的惩罚越大，$C$越小，对误分类的惩罚越小。</p><p>也就是说，我们希望$\frac{1}{2}||w||_2^2$尽量小，误分类的点尽可能的少。C是协调两者关系的正则化惩罚系数。在实际应用中，需要调参来选择。</p><h2 id=svm编程实现><a href=#svm%e7%bc%96%e7%a8%8b%e5%ae%9e%e7%8e%b0 class=header-anchor></a>SVM编程实现</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-matlab data-lang=matlab><span class=line><span class=cl><span class=c>%% 生成测试数据</span>
</span></span><span class=line><span class=cl><span class=n>classCount</span><span class=p>=</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>p</span><span class=p>=</span> <span class=mi>100</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>bound</span> <span class=p>=[</span><span class=mi>0</span> <span class=mi>10</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=p>=[</span><span class=c>...</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>]</span><span class=o>+</span> <span class=nb>randn</span><span class=p>(</span><span class=n>p</span><span class=p>,</span><span class=mi>2</span><span class=p>),</span><span class=o>-</span><span class=mi>1</span><span class=o>*</span><span class=nb>ones</span><span class=p>(</span><span class=n>p</span><span class=p>,</span><span class=mi>1</span><span class=p>);</span><span class=c>...</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span><span class=mi>6</span><span class=p>]</span><span class=o>+</span> <span class=nb>randn</span><span class=p>(</span><span class=n>p</span><span class=p>,</span><span class=mi>2</span><span class=p>),</span><span class=o>+</span><span class=mi>1</span><span class=o>*</span><span class=nb>ones</span><span class=p>(</span><span class=n>p</span><span class=p>,</span><span class=mi>1</span><span class=p>);</span><span class=c>...</span>
</span></span><span class=line><span class=cl>    <span class=p>];</span>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>=</span> <span class=n>data</span><span class=p>(:,</span><span class=mi>1</span><span class=p>:</span><span class=k>end</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=p>=</span> <span class=n>data</span><span class=p>(:,</span><span class=k>end</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c>%% 显示生成的测试数据</span>
</span></span><span class=line><span class=cl><span class=n>figure</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>clf</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>gscatter</span><span class=p>(</span><span class=n>X</span><span class=p>(:,</span><span class=mi>1</span><span class=p>),</span> <span class=n>X</span><span class=p>(:,</span><span class=mi>2</span><span class=p>),</span> <span class=n>Y</span><span class=p>,</span> <span class=s>&#39;rb&#39;</span><span class=p>,</span> <span class=s>&#39;X+&#39;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>legend</span><span class=p>({</span><span class=s>&#39;分类-1&#39;</span><span class=p>,</span> <span class=s>&#39;分类+1&#39;</span><span class=p>});</span>
</span></span><span class=line><span class=cl><span class=n>title</span><span class=p>(</span>&#34;原始数据散点图&#34;<span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>xlim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>ylim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c>%% 拆分训练集和测试集</span>
</span></span><span class=line><span class=cl><span class=n>trainIndex</span> <span class=p>=</span> <span class=p>(</span><span class=nb>mod</span><span class=p>(</span><span class=mi>1</span><span class=p>:</span><span class=nb>size</span><span class=p>(</span><span class=n>X</span><span class=p>,</span><span class=mi>1</span><span class=p>),</span><span class=mi>3</span><span class=p>)</span><span class=o>==</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>testIndex</span> <span class=p>=</span> <span class=o>~</span><span class=n>trainIndex</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Xtrain</span><span class=p>=</span><span class=n>X</span><span class=p>(</span><span class=n>trainIndex</span><span class=p>,:);</span>
</span></span><span class=line><span class=cl><span class=n>Ytrain</span><span class=p>=</span><span class=n>Y</span><span class=p>(</span><span class=n>trainIndex</span><span class=p>,:);</span>
</span></span><span class=line><span class=cl><span class=n>Xtest</span><span class=p>=</span><span class=n>X</span><span class=p>(</span><span class=n>testIndex</span><span class=p>,:);</span>
</span></span><span class=line><span class=cl><span class=n>Ytest</span><span class=p>=</span><span class=n>Y</span><span class=p>(</span><span class=n>testIndex</span><span class=p>,:);</span>
</span></span><span class=line><span class=cl><span class=c>%% 将拆分的结果展示</span>
</span></span><span class=line><span class=cl><span class=n>figure</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>clf</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>hold</span> <span class=n>on</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>gscatter</span><span class=p>(</span><span class=n>Xtrain</span><span class=p>(:,</span><span class=mi>1</span><span class=p>),</span><span class=n>Xtrain</span><span class=p>(:,</span><span class=mi>2</span><span class=p>),</span><span class=n>Ytrain</span><span class=p>,</span><span class=s>&#39;rb&#39;</span><span class=p>,</span><span class=s>&#39;X+&#39;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>scatter</span><span class=p>(</span><span class=n>Xtest</span><span class=p>(:,</span><span class=mi>1</span><span class=p>),</span><span class=n>Xtest</span><span class=p>(:,</span><span class=mi>2</span><span class=p>),</span><span class=s>&#39;k.&#39;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>hold</span> <span class=n>off</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>legend</span><span class=p>({</span><span class=s>&#39;分类-1&#39;</span><span class=p>,</span><span class=s>&#39;分类+1&#39;</span><span class=p>,</span><span class=s>&#39;测试数据&#39;</span><span class=p>});</span>
</span></span><span class=line><span class=cl><span class=n>title</span><span class=p>(</span>&#34;划分测试数据后的散点图&#34;<span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>xlim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>ylim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c>%% 使用SVM进行训练</span>
</span></span><span class=line><span class=cl><span class=n>svm</span><span class=p>=</span><span class=n>fitcsvm</span><span class=p>(</span><span class=n>Xtrain</span><span class=p>,</span><span class=n>Ytrain</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c>%% 展示SVM训练的结果</span>
</span></span><span class=line><span class=cl><span class=n>figure</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>clf</span><span class=p>;</span> 
</span></span><span class=line><span class=cl><span class=n>gscatter</span><span class=p>(</span><span class=n>Xtrain</span><span class=p>(:,</span><span class=mi>1</span><span class=p>),</span> <span class=n>Xtrain</span><span class=p>(:,</span> <span class=mi>2</span><span class=p>),</span> <span class=n>Ytrain</span><span class=p>,</span> <span class=s>&#39;rb&#39;</span><span class=p>,</span> <span class=s>&#39;X+&#39;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>hold</span> <span class=n>on</span><span class=p>;</span> 
</span></span><span class=line><span class=cl><span class=n>gscatter</span><span class=p>(</span><span class=n>svm</span><span class=p>.</span><span class=n>SupportVectors</span><span class=p>(:,</span><span class=mi>1</span><span class=p>),</span> <span class=n>svm</span><span class=p>.</span><span class=n>SupportVectors</span><span class=p>(:,</span><span class=mi>2</span><span class=p>),</span><span class=n>svm</span><span class=p>.</span><span class=n>SupportVectorLabels</span><span class=p>,</span><span class=s>&#39;rb&#39;</span><span class=p>,</span><span class=s>&#39;oo&#39;</span><span class=p>,</span><span class=mi>13</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>xg</span> <span class=p>=</span> <span class=n>bound</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>yg</span> <span class=p>=</span> <span class=p>[</span><span class=o>-</span><span class=n>svm</span><span class=p>.</span><span class=n>Bias</span><span class=o>/</span><span class=n>svm</span><span class=p>.</span><span class=n>Beta</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span> <span class=o>-</span><span class=n>svm</span><span class=p>.</span><span class=n>Beta</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=o>/</span><span class=n>svm</span><span class=p>.</span><span class=n>Beta</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=n>bound</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>-</span><span class=n>svm</span><span class=p>.</span><span class=n>Bias</span><span class=o>/</span><span class=n>svm</span><span class=p>.</span><span class=n>Beta</span><span class=p>(</span><span class=mi>2</span><span class=p>)];</span>
</span></span><span class=line><span class=cl><span class=n>plot</span><span class=p>(</span><span class=n>xg</span><span class=p>,</span> <span class=n>yg</span><span class=p>,</span> <span class=s>&#39;g&#39;</span><span class=p>,</span> <span class=s>&#39;Linewidth&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>delta</span> <span class=p>=</span> <span class=o>-</span><span class=n>svm</span><span class=p>.</span><span class=n>Beta</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=o>/</span><span class=n>svm</span><span class=p>.</span><span class=n>Beta</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>*</span><span class=n>svm</span><span class=p>.</span><span class=n>SupportVectors</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>svm</span><span class=p>.</span><span class=n>SupportVectors</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span><span class=o>-</span><span class=n>svm</span><span class=p>.</span><span class=n>Bias</span><span class=o>/</span><span class=n>svm</span><span class=p>.</span><span class=n>Beta</span><span class=p>(</span><span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>plot</span><span class=p>(</span><span class=n>xg</span><span class=p>,</span> <span class=n>yg</span><span class=o>-</span><span class=n>delta</span><span class=p>,</span> <span class=s>&#39;--g&#39;</span><span class=p>,</span> <span class=s>&#39;LineWidth&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span> 
</span></span><span class=line><span class=cl><span class=n>plot</span><span class=p>(</span><span class=n>xg</span><span class=p>,</span> <span class=n>yg</span><span class=o>+</span><span class=n>delta</span><span class=p>,</span> <span class=s>&#39;--g&#39;</span><span class=p>,</span> <span class=s>&#39;LineWidth&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span> 
</span></span><span class=line><span class=cl><span class=n>hold</span> <span class=n>off</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>xlim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>ylim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>legend</span><span class=p>({</span><span class=s>&#39;分类-1&#39;</span><span class=p>,</span> <span class=s>&#39;分类+1&#39;</span><span class=p>,</span> <span class=s>&#39;支持向量-1&#39;</span><span class=p>,</span> <span class=s>&#39;支持向量+1&#39;</span><span class=p>,</span> <span class=s>&#39;超平面&#39;</span><span class=p>,</span> <span class=s>&#39;超平面-1&#39;</span><span class=p>,</span> <span class=s>&#39;超平面+1&#39;</span><span class=p>});</span>
</span></span><span class=line><span class=cl><span class=n>title</span><span class=p>(</span>&#34;<span class=n>SVM训练后的散点图</span>&#34;<span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c>%% 使用训练好的模型进行预测</span>
</span></span><span class=line><span class=cl><span class=n>Ypred</span> <span class=p>=</span> <span class=n>predict</span><span class=p>(</span><span class=n>svm</span><span class=p>,</span> <span class=n>Xtest</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c>%% 绘制预测后的结果</span>
</span></span><span class=line><span class=cl><span class=n>figure</span><span class=p>(</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>clf</span><span class=p>;</span> 
</span></span><span class=line><span class=cl><span class=n>gscatter</span><span class=p>(</span><span class=n>Xtest</span><span class=p>(:,</span><span class=mi>1</span><span class=p>),</span> <span class=n>Xtest</span><span class=p>(:,</span> <span class=mi>2</span><span class=p>),</span> <span class=n>Ypred</span><span class=p>,</span> <span class=s>&#39;rb&#39;</span><span class=p>,</span> <span class=s>&#39;X+&#39;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>hold</span> <span class=n>on</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>g</span> <span class=p>=</span> <span class=n>gscatter</span><span class=p>(</span><span class=n>svm</span><span class=p>.</span><span class=n>SupportVectors</span><span class=p>(:,</span><span class=mi>1</span><span class=p>),</span> <span class=n>svm</span><span class=p>.</span><span class=n>SupportVectors</span><span class=p>(:,</span><span class=mi>2</span><span class=p>),</span> <span class=n>svm</span><span class=p>.</span><span class=n>SupportVectorLabels</span><span class=p>,</span> <span class=s>&#39;rb&#39;</span><span class=p>,</span><span class=s>&#39;oo&#39;</span><span class=p>,</span><span class=mi>13</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>plot</span><span class=p>(</span><span class=n>xg</span><span class=p>,</span> <span class=n>yg</span><span class=p>,</span> <span class=s>&#39;g&#39;</span><span class=p>,</span> <span class=s>&#39;Linewidth&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>plot</span><span class=p>(</span><span class=n>xg</span><span class=p>,</span> <span class=n>yg</span><span class=o>-</span><span class=n>delta</span><span class=p>,</span> <span class=s>&#39;--g&#39;</span><span class=p>,</span> <span class=s>&#39;Linewidth&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>plot</span><span class=p>(</span><span class=n>xg</span><span class=p>,</span> <span class=n>yg</span><span class=o>+</span><span class=n>delta</span><span class=p>,</span> <span class=s>&#39;--g&#39;</span><span class=p>,</span> <span class=s>&#39;Linewidth&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>hold</span> <span class=n>off</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>xlim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>ylim</span><span class=p>(</span><span class=n>bound</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>legend</span><span class=p>({</span><span class=s>&#39;分类-1&#39;</span><span class=p>,</span> <span class=s>&#39;分类+1&#39;</span><span class=p>,</span> <span class=s>&#39;支持向量-1&#39;</span><span class=p>,</span> <span class=s>&#39;支持向量+1&#39;</span><span class=p>,</span> <span class=s>&#39;超平面&#39;</span><span class=p>,</span> <span class=s>&#39;超平面-1&#39;</span><span class=p>,</span> <span class=s>&#39;超平面+1&#39;</span><span class=p>});</span>
</span></span><span class=line><span class=cl><span class=n>title</span><span class=p>(</span>&#34;<span class=n>SVM预测后的散点图</span>&#34;<span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c>%% 计算误差</span>
</span></span><span class=line><span class=cl><span class=n>fprintf</span><span class=p>(</span><span class=s>&#39;正确率为：%.2f%%\n&#39;</span><span class=p>,(</span><span class=n>sum</span><span class=p>(</span><span class=n>Ypred</span><span class=o>==</span><span class=n>Ytest</span><span class=p>)</span><span class=o>/</span><span class=nb>numel</span><span class=p>(</span><span class=n>Ytest</span><span class=p>))</span><span class=o>.*</span><span class=mi>100</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/4.png width=700 height=521 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/4_hu_ad6b3e3724079201.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/4_hu_661d237d39149284.png 1024w" loading=lazy alt=原始数据散点图 class=gallery-image data-flex-grow=134 data-flex-basis=322px></p><p><img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/5.png width=700 height=520 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/5_hu_9e77e1b3d168e3a9.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/5_hu_db2f9cbfca0dd610.png 1024w" loading=lazy alt=SVM训练后的散点图 class=gallery-image data-flex-grow=134 data-flex-basis=323px> <img src=/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/6.png width=700 height=527 srcset="/p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/6_hu_8447ac52b2d0c98d.png 480w, /p/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/IMAGE/6_hu_4c45fd3b17ecc87e.png 1024w" loading=lazy alt=SVM预测后的散点图 class=gallery-image data-flex-grow=132 data-flex-basis=318px></p><h2 id=svm实现多分类><a href=#svm%e5%ae%9e%e7%8e%b0%e5%a4%9a%e5%88%86%e7%b1%bb class=header-anchor></a>SVM实现多分类</h2><p>SVM算法最初是为二值分类问题设计的，当处理多类问题时，就需要构造合适的多类分类器。</p><p>目前，构造SVM多类分类器的方法主要有两类：</p><p>（1）直接法，直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。这种方法看似简单，但其计算复杂度比较高，实现起来比较困难，只适合用于小型问题中；</p><p>（2）间接法，主要是通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one和one-against-all两种。</p><h3 id=一对多法ovr><a href=#%e4%b8%80%e5%af%b9%e5%a4%9a%e6%b3%95ovr class=header-anchor></a>一对多法（OVR）</h3><p>训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。分类时将未知样本分类为具有最大分类函数值的那类。</p><p>假如我有四类要划分（也就是4个Label），他们是A、B、C、D。</p><p>于是我在抽取训练集的时候，分别抽取</p><ol><li>A所对应的向量作为正集，B，C，D所对应的向量作为负集；</li><li>B所对应的向量作为正集，A，C，D所对应的向量作为负集；</li><li>C所对应的向量作为正集，A，B，D所对应的向量作为负集；</li><li>D所对应的向量作为正集，A，B，C所对应的向量作为负集；</li></ol><p>使用这四个训练集分别进行训练，然后的得到四个训练结果文件。在测试的时候，把对应的测试向量分别利用这四个训练结果文件进行测试。最后每个测试都有一个结果f1(x),f2(x),f3(x),f4(x)。</p><p>于是最终的结果便是这四个值中最大的一个作为分类结果。</p><h3 id=一对一法ovo><a href=#%e4%b8%80%e5%af%b9%e4%b8%80%e6%b3%95ovo class=header-anchor></a>一对一法（OVO）</h3><p>一般都是用一对多法，这里就不展开了，知道有这个东西就行。</p><h2 id=参考资料><a href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99 class=header-anchor></a>参考资料</h2><ul><li><a class=link href=https://zhuanlan.zhihu.com/p/31886934 target=_blank rel=noopener>支持向量机（SVM）——原理篇 - 知乎</a></li><li><a class=link href=https://www.cnblogs.com/pinard/p/6097604.html target=_blank rel=noopener>支持向量机原理(一) 线性支持向量机 - 刘建平Pinard - 博客园</a> 等同系列文章</li><li><a class=link href=https://www.bilibili.com/video/BV13r4y1z7AG/ target=_blank rel=noopener>【数之道25】机器学习必经之路-SVM支持向量机的数学精华_哔哩哔哩_bilibili</a> 等同系列视频</li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/>数据挖掘</a>
<a href=/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/>交叉验证</a>
<a href=/tags/svm/>SVM</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/><div class=article-image><img src=/p/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/98259515.80d66336683193280f34d36beb46fd91.webp width=1414 height=1000 loading=lazy alt="Featured image of post 特征工程学习笔记" data-hash="md5-gNZjNmgxkygPNNNr60b9kQ=="></div><div class=article-details><h2 class=article-title>特征工程学习笔记</h2></div></a></article><article class=has-image><a href=/p/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/><div class=article-image><img src=/p/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/95446530.ad1a6ba33c608214a1fc147775fe1b05.webp width=1882 height=1217 loading=lazy alt="Featured image of post 回归分析学习笔记" data-hash="md5-rRprozxgghSh/BR3df4bBQ=="></div><div class=article-details><h2 class=article-title>回归分析学习笔记</h2></div></a></article><article class=has-image><a href=/p/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/><div class=article-image><img src=/p/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/97701948.d2f9ff1606e3b06124ed2ee081a6ad2a.webp width=1883 height=1257 loading=lazy alt="Featured image of post 聚类算法学习笔记" data-hash="md5-0vn/FgbjsGEk7S7ggaatKg=="></div><div class=article-details><h2 class=article-title>聚类算法学习笔记</h2></div></a></article><article class=has-image><a href=/p/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%AC%94%E8%AE%B0/><div class=article-image><img src=/p/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%AC%94%E8%AE%B0/94861285.1081b8580023261482a7b4e7156e1bc9.webp width=1447 height=1023 loading=lazy alt="Featured image of post 数据可视化笔记" data-hash="md5-EIG4WAAjJhSCp7TnFW4byQ=="></div><div class=article-details><h2 class=article-title>数据可视化笔记</h2></div></a></article></div></div></aside><link href=//unpkg.com/@waline/client@v3/dist/waline.css rel=stylesheet><div id=waline class=waline-container></div><style>.waline-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding);--waline-font-size:var(--article-font-size)}.waline-container .wl-count{color:var(--card-text-color-main)}</style><script type=module>
    import { init } from 'https://unpkg.com/@waline/client@v3/dist/waline.js';

    setTimeout(function () {
        
        init({"dark":"html[data-scheme=\"dark\"]","el":"#waline","emoji":["https://unpkg.com/@waline/emojis@1.2.0/weibo"],"lang":"zh-CN","locale":{"admin":"Admin","placeholder":null},"requiredMeta":["name","email","url"],"serverURL":"https://waline.lbqaq.top/"});
    }, 300);


</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 luoboQAQ</section><section class=powerby><a href=https://beian.miit.gov.cn>苏ICP备2021037116号</a><br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://npm.elemecdn.com/node-vibrant@latest/dist/vibrant.min.js crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e);const t=document.createElement("link");t.href="https://cdn.jsdelivr.net/npm/@callmebill/lxgw-wenkai-web@latest/style.css",t.type="text/css",t.rel="stylesheet",document.head.appendChild(t)})()</script></body></html>